{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mlTDs60E9aFM",
        "6vnVOrfPOoU7",
        "jLGJRYeQPULU",
        "vgJo5nhcPa3j"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuelebompani/yelp-similarity/blob/main/AMD_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnifhMTt9IVg"
      },
      "source": [
        "# **AMD Project**\n",
        "## Similar items\n",
        "### Samuele Bompani 984322"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Global variables*"
      ],
      "metadata": {
        "id": "IqUuqU2PmWzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slow =  {\n",
        "  \"n\": 100000,\n",
        "  \"k\": 5,\n",
        "  \"h\": 100,\n",
        "  \"b\": 20\n",
        "}\n",
        "fast = {\n",
        "  \"n\": 100000,\n",
        "  \"k\": 5,\n",
        "  \"h\": 10,\n",
        "  \"b\": 4\n",
        "}\n",
        "variables = slow"
      ],
      "metadata": {
        "id": "Um9uHA-kmU5b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTDs60E9aFM"
      },
      "source": [
        "# *Import Libraries*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYdRYx1u9FvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e42f0b-f31f-4da0-d9e4-23ea59f5abff"
      },
      "source": [
        "! pip install -q pyspark\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import files\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pyspark"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = pyspark.sql.SparkSession.builder.master('local[*]').appName(\"yelp-similarity\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "JSsI4OsBsTip"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Import the dataset*"
      ],
      "metadata": {
        "id": "6Zj81pokDDJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Upload the credentials*"
      ],
      "metadata": {
        "id": "6vnVOrfPOoU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload a file named kaggle.json with your Kaggle credentials"
      ],
      "metadata": {
        "id": "0qNq_H-IO272"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()\n",
        "print(\"ok\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "EbZRN7LUGbeo",
        "outputId": "566c1af8-5c6c-405a-9536-67b8d0caba3b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af29fbfb-9c2d-4053-99a3-260e36f7b7d0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af29fbfb-9c2d-4053-99a3-260e36f7b7d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! mv kaggle.json ~/.kaggle/ #copying kaggle.json\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json #reading the file with full access"
      ],
      "metadata": {
        "id": "aS1dNqusGqgt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Download the dataset*"
      ],
      "metadata": {
        "id": "jLGJRYeQPULU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -f yelp_academic_dataset_review.json -d yelp-dataset/yelp-dataset #downloading the compatition dataset\n",
        "! unzip -n yelp_academic_dataset_review.json.zip"
      ],
      "metadata": {
        "id": "bQgd0tUIHmNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcef28b-8b4a-4bf4-9c9b-ae0ee67c8f0e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yelp_academic_dataset_review.json.zip to /content\n",
            "100% 2.06G/2.07G [00:24<00:00, 119MB/s]\n",
            "100% 2.07G/2.07G [00:25<00:00, 88.8MB/s]\n",
            "Archive:  yelp_academic_dataset_review.json.zip\n",
            "  inflating: yelp_academic_dataset_review.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Open the dataset file*"
      ],
      "metadata": {
        "id": "vgJo5nhcPa3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dimension of the subset\n",
        "n_rows = variables.get(\"n\")\n",
        "data_spark = spark.read.json(\"yelp_academic_dataset_review.json\").limit(n_rows)\n",
        "data_spark.printSchema()"
      ],
      "metadata": {
        "id": "5wvTnZYAsmrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0581d1a0-ae99-446a-c651-27dd280a3373"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- business_id: string (nullable = true)\n",
            " |-- cool: long (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- funny: long (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- stars: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- useful: long (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Finding similar items*"
      ],
      "metadata": {
        "id": "bZLMVVA7a8HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMC1SA7OklSs",
        "outputId": "262dfef8-b540-45f6-8837-43f6e655074b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce text to tokens"
      ],
      "metadata": {
        "id": "IVg7akPAA4yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-shingles"
      ],
      "metadata": {
        "id": "TTUa_SdJq8oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_shingles(text, k):\n",
        "  shingles = []\n",
        "  ks_string = \" \".join(text)\n",
        "  for i in range(len(ks_string)-k+1):\n",
        "    shingles.append(ks_string[i:(i+k)])\n",
        "  return shingles"
      ],
      "metadata": {
        "id": "njotcAX0q7Sc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization and stopwords removal"
      ],
      "metadata": {
        "id": "mnzSr69Wtr48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = stopwords.words('english')\n",
        "\n",
        "# Remove whitespaces and punctuation\n",
        "def normalize_text(text):\n",
        "  return text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def tokenize_text(text):\n",
        "  filtered = []\n",
        "  for w in normalize_text(text).split():\n",
        "    # Remove stop words\n",
        "    if w not in sw:\n",
        "      filtered.append(w)\n",
        "  # Apply k-shingles\n",
        "  return k_shingles(filtered, variables.get(\"k\"))"
      ],
      "metadata": {
        "id": "vUWeBM4G2Tgq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_rep = data_spark.repartition(\"text\")\n",
        "data_sel = data_rep.select(data_rep.text)\n",
        "text_w_index = data_sel.rdd.map(lambda x: x.text).zipWithIndex()\n",
        "# Apply the previous defined functions\n",
        "tuples = text_w_index.flatMap(lambda x: map(lambda y: (y, x[1]), tokenize_text(x[0])))"
      ],
      "metadata": {
        "id": "xRLBY7j9Ksir"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minhash"
      ],
      "metadata": {
        "id": "vQNZB--PbAl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group touples by words"
      ],
      "metadata": {
        "id": "pHgu_4X02ZZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tuples with the shape: (ns, [sd1, sd2, ...])\n",
        "# with ns = number associated to a shingle s\n",
        "# and  sdi = number associated to the document i, if s is present in it\n",
        "grouped_tuples = tuples.groupByKey().zipWithIndex().map(lambda x: (x[1], x[0][1]))"
      ],
      "metadata": {
        "id": "RHZm53GB2Yy7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count the tokens"
      ],
      "metadata": {
        "id": "Y7uBUVgB4NkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_count = grouped_tuples.count()\n",
        "print(\"Number of distinct shingles: \"+str(token_count))"
      ],
      "metadata": {
        "id": "wsJTUFca4Rb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25acecc-a72f-4b2c-de3d-9a2bb801091e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct shingles: 418945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hash functions creation"
      ],
      "metadata": {
        "id": "ja68_YRX4qM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of hash function\n",
        "n_hash = variables.get(\"h\")"
      ],
      "metadata": {
        "id": "e5XwUvxVPt4_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random as rd\n",
        "def h(a, b):\n",
        "  def new_h(x):\n",
        "    return (a * x + b) % token_count\n",
        "  return new_h\n",
        "\n",
        "hash_list = []\n",
        "for i in range(n_hash):\n",
        "  # a and b are two (pseudo)random numbers\n",
        "  hash_list.append(h(rd.randint(0,token_count), rd.randint(0,token_count)))"
      ],
      "metadata": {
        "id": "ne-o6SypO6Cr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply hash functions"
      ],
      "metadata": {
        "id": "eF-oHzQqW8cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seqOpHash(d, x):\n",
        "  for i, h in enumerate(hash_list):\n",
        "    # apply the hash function h\n",
        "    val = h(x[0])\n",
        "    for j in x[1]:\n",
        "      # keys for d are tuples with this shape:\n",
        "      # (number of the hash function, number of the document)\n",
        "      if (i, j) not in d:\n",
        "        d[(i, j)] = val\n",
        "      else:\n",
        "        if(val < d.get((i, j))):\n",
        "          d[(i, j)] = val\n",
        "  return d\n",
        "\n",
        "def combOpHash(x, y):\n",
        "  return y\n",
        "\n",
        "# Apply the minhash algorithm\n",
        "min_hash = grouped_tuples.aggregate({}, seqOpHash, combOpHash)"
      ],
      "metadata": {
        "id": "ucWGvm8IoUhK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the vectors"
      ],
      "metadata": {
        "id": "b8I07aFHXGrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "par = []\n",
        "for i in min_hash:\n",
        "  par.append((i, min_hash[i]))\n",
        "d = sc.parallelize(par)"
      ],
      "metadata": {
        "id": "o_icb_2d5Gs-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = d.groupBy(lambda x: x[0][1])\n",
        "# Create the similarity matrix\n",
        "vecs = grouped.map(lambda x: (x[0], list(map(lambda y: y[1], x[1]))))"
      ],
      "metadata": {
        "id": "gPgbwOpWaUwl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSH"
      ],
      "metadata": {
        "id": "1oK6UZ_Zcha0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trashold choice"
      ],
      "metadata": {
        "id": "1LdJl1wWeApk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = 4\n",
        "r = int(n_hash/b)\n",
        "t = (1/b)**(1/r)\n",
        "print(\"b: \", b, \"\\nr: \", r, \"\\nt: \", round(t, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UaZ5SUYcgO5",
        "outputId": "5b46f1a7-a38c-4ad3-bb82-ff8891e0914e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b:  4 \n",
            "r:  25 \n",
            "t:  0.9461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split vectors"
      ],
      "metadata": {
        "id": "MHZUJ5auhZk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_vector(vec):\n",
        "  sub_vecs = []\n",
        "  for i in range(0, len(vec), r):\n",
        "    sub_vecs.append(str(vec[i : i+r]))\n",
        "  return sub_vecs"
      ],
      "metadata": {
        "id": "qzzTCs0kdlHd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Candidate pairs identification"
      ],
      "metadata": {
        "id": "ix81dCX_ij1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seqOp(x, y):\n",
        "  for i, s in enumerate(y[1]):\n",
        "    if s not in x[i].keys():\n",
        "      x[i][s] = [y[0]]\n",
        "    else:\n",
        "      x[i][s].append(y[0])\n",
        "  return x\n",
        "\n",
        "def combOp(x, y):\n",
        "  return y\n",
        "\n",
        "subv = vecs.map(lambda x: (x[0], split_vector(x[1])))\n",
        "# Populate the buckets\n",
        "bucks = subv.aggregate(([{}]*b), seqOp, combOp)"
      ],
      "metadata": {
        "id": "W3-_3NjEyDJm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def find_candidates(buckets):\n",
        "  candidates = []\n",
        "  for bucket in buckets:\n",
        "    for h in bucket.keys():\n",
        "      if len(bucket[h]) > 1:\n",
        "        for pair in combinations(bucket[h], 2):\n",
        "          candidates.append(pair)\n",
        "  return candidates"
      ],
      "metadata": {
        "id": "trrfBSTNO1g_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = sc.parallelize(find_candidates(bucks)).distinct()"
      ],
      "metadata": {
        "id": "DSaHPsbDP1Gk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter by the trashold"
      ],
      "metadata": {
        "id": "VuquqiijRwph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vs = vecs.collect()\n",
        "\n",
        "def agree(x, y):\n",
        "  intersection = 0\n",
        "  for i, el in enumerate(x):\n",
        "    if(y[i] == el):\n",
        "      intersection += 1\n",
        "  return intersection / len(x)\n",
        "\n",
        "def compare(x, y):\n",
        "  vx = list(filter(lambda i: i[0]==x, vs))[0][1]\n",
        "  vy = list(filter(lambda i: i[0]==y, vs))[0][1]\n",
        "  return (x, y, agree(vx, vy))\n",
        "\n",
        "candidates_agr = candidates.map(lambda x: compare(x[0], x[1]))"
      ],
      "metadata": {
        "id": "ln9yaA8hI4U0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_candidates = candidates_agr.filter(lambda x: (x[2] > t)).collect()"
      ],
      "metadata": {
        "id": "1k7bvVjkK-Sx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Evaluation*"
      ],
      "metadata": {
        "id": "yVJjtnmmjKF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jaccard similarity"
      ],
      "metadata": {
        "id": "8Q6_uc6XjXK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(x, y):\n",
        "  xs = set(x)\n",
        "  xy = set(y)\n",
        "  intersection = len(xs.intersection(xy))\n",
        "  union = len(xs.union(xy))\n",
        "  if union == 0:\n",
        "    return 0\n",
        "  return intersection/union\n"
      ],
      "metadata": {
        "id": "XjinSO6uplVA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "qDtqYVWWjaxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_w_index.map(lambda x: (x[1], x[0])).collectAsMap()\n",
        "errors = []\n",
        "jac_values= []\n",
        "for i in filtered_candidates:\n",
        "  x = texts.get(i[0])\n",
        "  y = texts.get(i[1])\n",
        "  j = jaccard(tokenize_text(x),\n",
        "        tokenize_text(y))\n",
        "  errors.append(abs(i[2]-j))\n",
        "  jac_values.append(j)\n",
        "  print(\"1- \",x,\"\\n2-\",y,\"\\n\\nJACCARD:\",j,\"\\nESTIMATION\",i[2],\"\\n\")"
      ],
      "metadata": {
        "id": "9tUTDZiXp5xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13d38af-7caf-4ae2-ad5c-5473b9c4d788"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-  I gave up eating meat but I get cravings for burgers. I'm so happy I found the  black bean burger. It's so good, chargrilled and you can add any toppings as you would for the beef burgers.\n",
            "I've had it 3 times and have not been disappointed. It's a pretty big burger and with fries on the side it's a great lunch for about $8. \n",
            "2- I gave up eating meat but I get cravings for burgers. I'm so happy I found the  black bean burger. It's so good, chargrilled and you can add any toppings as you would for the beef burgers.\n",
            "I've had it 3 times and have not been disappointed. It's a pretty big burger and with fries on the side it's a great lunch for about $8. \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  I will first start by saying that the service here is some of the best I've ever had. Friendly, knowledgable and there for anything you ask for immediately without being over bearing.\n",
            "Now to the food, we started off with the antipasto, a weekend special, and it was amazing. Prosciutto, mortadella, sharp provolone, stuffed peppers and many other thing, marinated in a delicious oil, it was perfect. \n",
            "I got the porterhouse steak special next topped with Gorgonzola and an amazing steak sauce. Cooked veggies and mashed potatoes on the side, it was perfectly cooked and everything went perfect with the next thing. My girlfriend got the lasagna which had the best mozzarella cheese I've had, and the sauce was also amazing. \n",
            "We got the Tierra massou finally and that was perfect as well. \n",
            "Between the perfect food and the great service I would highly recommend this place to anyone. \n",
            "2- I will first start by saying that the service here is some of the best I've ever had. Friendly, knowledgable and there for anything you ask for immediately without being over bearing.\n",
            "Now to the food, we started off with the antipasto, a weekend special, and it was amazing. Prosciutto, mortadella, sharp provolone, stuffed peppers and many other things, marinated in a delicious oil, it was perfect. \n",
            "I got the porterhouse steak special next topped with Gorgonzola and an amazing steak sauce. Cooked veggies and mashed potatoes on the side, it was perfectly cooked and everything went perfect with the next thing. My girlfriend got the lasagna which had the best mozzarella cheese I've had, and the sauce was also amazing. \n",
            "We got the Tierra massou finally and that was perfect as well. \n",
            "Between the perfect food and the great service I would highly recommend this place to anyone. \n",
            "\n",
            "JACCARD: 0.9840637450199203 \n",
            "ESTIMATION 0.98 \n",
            "\n",
            "1-  While I was moving in and had all my stuff on my patio the inspector left a note that was threatening :\n",
            "Stating I had inappropriate items on my patio \n",
            "Trash left out \n",
            "EXCUSE me but I was moving !!!!!!\n",
            "So I went to the office and a woman named Deborah helped me ..\n",
            "Very condescending .. Acted like I had no right to complain about my note...\n",
            "Then I asked for a copy of my lease.. Oops again .... \n",
            "We're sorry you can't have that it's under lock and key!!! WHAT!!!!!\n",
            "This volley of info and rudeness continued until she came out and said they were closing the office for the night!!\n",
            "WOW what a difference from my rental I'm Asheville NC.. Friendly clean always remembered who we were even though it was a huge complex..\n",
            "Ohhh , they will be friendly when you are looking but once you sign the dotted line ....not so great!!!!\n",
            "You're just a number , you mean nothing to SENTINAL CORP believe me or they would have a nicer staff and wouldn't have to threaten you when your trying to get all your stuff put away!!!! \n",
            "2- While I was moving in and had all my stuff on my patio the inspector left a note that was threatening :\n",
            "Stating I had inappropriate items on my patio \n",
            "Trash left out \n",
            "EXCUSE me but I was moving !!!!!!\n",
            "So I went to the office and a woman named Deborah helped me ..\n",
            "Very condescending .. Acted like I had no right to complain about my note...\n",
            "Then I asked for a copy of my lease.. Oops again .... \n",
            "We're sorry you can't have that it's under lock and key!!! WHAT!!!!!\n",
            "This volley of info and rudeness continued until she came out and said they were closing the office for the night!!\n",
            "WOW what a difference from my rental I'm Asheville NC.. Friendly clean always remembered who we were even though it was a huge complex..\n",
            "Ohhh , they will be friendly when you are looking but once you sign the dotted line ....not so great!!!!\n",
            "You're just a number , you mean nothing to SENTINAL CORP believe me or they would have a nicer staff and wouldn't have to threaten you when your trying to get all your stuff put away!!!! \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  I was going to order delivery but the guy on the phone convinced me there was a very long wait time of 45 minutes to an hour then asked if I was sure I wanted to order. So I'll take my business elsewhere. But I hear the food is really good. \n",
            "2- I was going to order delivery but the guy on the phone convinced me there was a very long wait time of 45 minutes to an hour then asked if I was sure I wanted to order. So I'll take my business elsewhere. But I hear the food is really good. \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  The Clearwater area has been in dire need for a sushi spot like this!\n",
            "\n",
            "This restaurant offers an excellent all you can eat sushi and hibachi menu along with plenty of appetizers and soups to choose from. For dinner the price is very reasonable at $17.95 per person and kids 4-8 are only $4.99! Can you even get a happy meal for that price? Our daughter loves sushi and Chicken Teriyaki so she was in heaven. If you aren't into sushi that's ok as you can choose from a wide array of dinner items.\n",
            "\n",
            "Please note this is not a buffet style place like many other places in the area. You place your order from the menu they give you and then they make the items for you and bring them out. This is better as you know they are making it fresh for you and it hasn't been sitting on some warmer exposed to the public with a chance of people breathing all over it.\n",
            "\n",
            "We went on a Monday night around 6:30 and it was nice and quiet as we were the only ones in the restaurant. The inside is very nicely decorated and doesn't quite feel like a Japanese restaurant with the tasteful decor they have.\n",
            "\n",
            "We had a few of the rolls on the menu including Spicy Tuna and Salmon rolls along with a Mexican roll off of the standard rolls menu. Each one was amazing and you could tell everything was fresh as it melted in your mouth and the fish had no smell whatsoever. The spicy rolls are not really spicy so if you like it hot ask for it Extra Spicy to kick it up a notch.\n",
            "\n",
            "Where the good rolls are at is in the Signature Rolls section which is included in the menu. I know some other places in Pinellas County where they charge you extra for these. We had a large variety including The Hawaii, Rainbow, Dancing Krab, Green Sarabay, Saki, Volcano and the Crunchy 2 in 1. Wow that sounds like a lot! Our favorite by far was the Volcano which was baked and topped with Krab and spicy mayo. I'm not usually a fan of cooked rolls but this was amazing. Another to recommend is the Crunchy 2 in 1. Our goal is to try every roll they have as the menu is quite extensive.\n",
            "\n",
            "Make sure to only order what you know you will eat as they will charge you for any pieces you leave up to .75 per piece I believe.\n",
            "\n",
            "The server was always smiling and very courteous and made us feel welcomed. By the time we left, the restaurant was starting to fill up.\n",
            "\n",
            "This is definitely a place to try if you are into sushi and looking for an all you can eat option. The sushi is actually better than other places in the area that don't off the AYCE option. \n",
            "2- The Clearwater area has been in dire need for a sushi spot like this!\n",
            "\n",
            "This restaurant offers an excellent all you can eat sushi and hibachi menu along with plenty of appetizers and soups to choose from. For dinner the price is very reasonable at $17.95 per person and kids 4-8 are only $4.99! Can you even get a happy meal for that price? Our daughter loves sushi and Chicken Teriyaki so she was in heaven. If you aren't into sushi that's ok as you can choose from a wide array of dinner items. \n",
            "\n",
            "Please note this is not a buffet style place like many other places in the area. You place your order from the menu they give you and then they make the items for you and bring them out. This is better as you know they are making it fresh for you and it hasn't been sitting on some warmer exposed to the public with a chance of people breathing all over it.\n",
            "\n",
            "We went on a Monday night around 6:30 and it was nice and quiet as we were the only ones in the restaurant. The inside is very nicely decorated and doesn't quite feel like a Japanese restaurant with the tasteful decor they have.\n",
            "\n",
            "We had a few of the rolls on the menu including Spicy Tuna and Salmon rolls along with a Mexican roll off of the standard rolls menu. Each one was amazing and you could tell everything was fresh as it melted in your mouth and the fish had no smell whatsoever. The spicy rolls are not really spicy so if you like it hot ask for it Extra Spicy to kick it up a notch.\n",
            "\n",
            "Where the good rolls are at is in the Signature Rolls section which is included in the menu. I know some other places in Pinellas County where they charge you extra for these. We had a large variety including The Hawaii, Rainbow, Dancing Krab, Green Sarabay, Saki, Volcano and the Crunchy 2 in 1. Wow that sounds like a lot! Our favorite by far was the Volcano which was baked and topped with Krab and spicy mayo. I'm not usually a fan of cooked rolls but this was amazing. Another to recommend is the Crunchy 2 in 1. Our goal is to try every roll they have as the menu is quite extensive.\n",
            "\n",
            "Make sure to only order what you know you will eat as they will charge you for any pieces you leave up to .75 per piece I believe.\n",
            "\n",
            "The server was always smiling and very courteous and made us feel welcomed. By the time we left, the restaurant was starting to fill up.\n",
            "\n",
            "This is definitely a place to try if you are into sushi and looking for an all you can eat option. The sushi is actually better than other places in the area that don't off the AYCE option. \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  Went to Philly Diner for dinner tonight. Service was horrible.  Ask the waiter for extra butter for the baked potato and by the time the butter came the potato was so cold, even the half melted butter wouldn't even melt the rest of the way. Took ten minutes to flag down our server for more soda since he never came back to check on us. Husband got the short ribs which was three pieces of meat. Ate one and started to eat the next but the remaining pieces were just fat and gristle. Complained to the server and was told the dinner would be taken off our bill but we had to pay for the sides. So how exactly did the \"sides\" almost cost as much as the dinner???? they took off $1.99. Bitched and they took off another 10%. Still NOT WORTH IT!!!. And all they said was sorry but it's our policy. Yes go ahead and laugh..... we are Seniors and eat in a lot of diners.  Never experienced anything like this before. RANT OVER. \n",
            "2- Service was horrible.  Ask the waiter for extra butter for the baked potato and by the time the butter came the potato was so cold, even the half melted butter wouldn't even melt the rest of the way. Took ten minutes to flag down our server for more soda since he never came back to check on us. Husband got the short ribs which was three pieces of meat. Ate one and started to eat the next but the remaining pieces were just fat and gristle. Complained to the server and was told the dinner would be taken off our bill but we had to pay for the sides. So how exactly did the \"sides\" almost cost as much as the dinner???? they took off $1.99. Bitched and they took off another 10%. Still NOT WORTH IT!!!. And all they said was sorry but it's our policy. Yes go ahead and laugh..... we are Seniors and eat in a lot of diners.  Never experienced anything like this before. \n",
            "\n",
            "JACCARD: 0.9421157684630739 \n",
            "ESTIMATION 0.95 \n",
            "\n",
            "1-  Wishing a happy, healthy holiday season to the family and staff of this priceless Italian eatery located in Newtown PA.\n",
            "\n",
            "Always greeted with a smile, always a great meal.\n",
            "\n",
            "Nice to be recognized and know what your food likes or food needs/requirements include. \n",
            "\n",
            "Hands down a wonderful go to for self, for family and for entertaining of friends and family. \n",
            "2- Wishing a happy, healthy holiday season to the family and staff of this priceless Italian eatery located in Newtown PA.\n",
            "\n",
            "Always greeted with a smile, always a great meal.\n",
            "\n",
            "Nice to be recognized and know what your food likes or food needs/requirements include. \n",
            "\n",
            "Hands down a wonderful go to for self, for family and for entertaining of friends and family. \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  Super friendly people and workers here!!! The food is great but they only two cooks and they work their hardest I come here every time I'm in the mood for something fast and delicious. They have a wide selection of stir fry and drinks with great pho. Don't listen to the bad reviews they obviously think it's a rich people place it's a great place. \n",
            "2- Super friendly people and workers here!!! The food is great but they only two cooks and they work their hardest I come here every time I'm in the mood for something fast and delicious. They have a wide selection of stir fry and drinks with great pho. Don't listen to the bad reviews they obviously think it's a rich people place it's a great people \n",
            "\n",
            "JACCARD: 0.9806763285024155 \n",
            "ESTIMATION 0.97 \n",
            "\n",
            "1-  I've been a fan of Malena's since she opened five years ago.  You can tell that she picks each of her pieces with care and experience.  In a store that sells 90% vintage merchandise (10% rockabilly apparel), you'll be hard-pressed to find anything below excellent condition.\n",
            "\n",
            "The boutique also showcases local fashion design talent such as Nicole Rae Styer.\n",
            "\n",
            "My favorite part about Malena's (and most other shops in West Chester) is their First Friday Event.  The first Friday of every month, the boutique stays open late, serves drinks and Hor D'oeuvres and has a big sale.  A great way to spend a friday!\n",
            "\n",
            "The prices are reasonable also, so you can find your one-of-a-kind item without breaking the bank. \n",
            "2- I've been a fan of Malena's since she opened five years ago.  You can tell that she picks each of her pieces with care and experience.  In a store that sells 90% vintage merchandise (10% rockabilly apparel), you'll be hard-pressed to find anything below excellent condition.\n",
            "\n",
            "The boutique also showcases local fashion design talent such as Nicole Ray Styer.\n",
            "\n",
            "My favorite part about Malena's (and most other shops in West Chester) is their First Friday Event.  The first Friday of every month, the boutique stays open late, serves drinks and Hor D'oeuvres and has a big sale.  A great way to spend a friday!\n",
            "\n",
            "The prices are reasonable also, so you can find your one-of-a-kind item without breaking the bank. \n",
            "\n",
            "JACCARD: 0.9779735682819384 \n",
            "ESTIMATION 0.99 \n",
            "\n",
            "1-  Certainly not worth the price. IMO food was not seasoned the way I expect an Italian restaurant to be. \n",
            "2- Certainly not worth the price. IMO food was not seasoned the way I expect an Italian restaurant to be. \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  This is hands down one of the best places to eat on the Eastern Main line. The service is impeccable- timely, polite, friendly and responsive. When I ordered the tofu pad Thai, the server asked if I was ok with egg in the dish. So conscientious! \n",
            "\n",
            "We eat here A LOT and have tried most of the menu. The soups are delicious as are the appetizers we have tried. Our favorite entrees are the curries, pad Thai, drunken noodles and some of their specials. Recently they had a Broad Street special and it was spectacular. We also love the apple salad. \n",
            "\n",
            "Highly HIGHLY recommend making this one of your regular spots!! \n",
            "2- This is hands down one of the best places to eat on the Eastern Main line. The service is impeccable- timely, polite, friendly and responsive. When I ordered the tofu pad Thai, the server asked if I was ok with egg in the dish. So conscientious! \n",
            "\n",
            "We eat here A LOT and have tried most of the menu. The soups are delicious as are the appetizers we have tried. Our favorite entrees are the curries, pad Thai, drunken noodles and some of their specials. Recently they had a Broad Street special and it was spectacular. We also love the apple salad. \n",
            "\n",
            "Highly HIGHLY recommend making this one of your regular spots!! \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n",
            "1-  Feel like I just took a trip to heaven and back \n",
            "This place is clean, professional and excellent therapists \n",
            "I had a body scrub, shampoo and Swedish massage \n",
            "Can't wait to come back and also try their food \n",
            "I would have given six stars if that was possible \n",
            "2- Feel like I just took a trip to heaven and back \n",
            "This place is clean, professional and excellent therapists \n",
            "I had a body scrub, shampoo and Swedish massage \n",
            "Can't wait to come back and also try their food \n",
            "I would have given six stars if that was possible \n",
            "\n",
            "JACCARD: 1.0 \n",
            "ESTIMATION 1.0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = len([e for e in errors if e == 0])\n",
        "print(\"Mean error: \", round(sum(errors) / len(errors), 4))\n",
        "print(\"Jaccard similarity mean value: \",\n",
        "  round(sum(jac_values) / len(jac_values), 4))\n",
        "print(\"Correct estimation: \", round(correct/len(errors),4),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcOeWqewi6IC",
        "outputId": "2629a82c-e672-4ee4-feb1-24ad8aa29f22"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean error:  0.0029\n",
            "Jaccard similarity mean value:  0.9904\n",
            "Correct estimation:  0.6667 %\n"
          ]
        }
      ]
    }
  ]
}